from flask import Flask, jsonify, request
from flask_cors import CORS  # <--- Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾
import subprocess
import shlex
import os
import signal
import atexit
import time

app = Flask(__name__)
CORS(app)

scrapy_processes = {}  # Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð² Scrapy Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹

@app.route('/')
def hello():
    return "Hello, this is your Scrapy Flask serveraaa!"

@app.route('/start-scrapy', methods=['POST'])
def start_scrapy():
    user_id = request.json.get("user_id")  # Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°, Ð½Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð»Ð¸ ÑƒÐ¶Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    if user_id in scrapy_processes and scrapy_processes[user_id].poll() is None:
        return jsonify({"status": f"Scrapy spider is already running for user {user_id}."}), 400

    data = request.json

    args = {
        "user": user_id, 
        "start_url": data.get("start_url"),
        "allowed_domains": data.get("allowed_domains"),
        "product_path": data.get("product_path"),
        "category_selector": data.get("category_selector"),
        "name_selector": data.get("name_selector"),
        "price_selector": data.get("price_selector"),
        "unit_selector": data.get("unit_selector"),
        "block_selector": data.get("block_selector"),
        "key_selector": data.get("key_selector"),
        "value_selector": data.get("value_selector"),
    }

    # ÐšÐ¾Ð¼Ð°Ð½Ð´Ð°
    cmd = "cd catching_materials && scrapy crawl spider_main"
    for key, value in args.items():
        if value is not None:
            cmd += f" -a {key}={shlex.quote(value)}"

    print(f"Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Scrapy Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {user_id}:")
    print(cmd)

    try:
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Scrapy ÐºÐ°Ðº Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        scrapy_process = subprocess.Popen(
            cmd, shell=True, stdout=subprocess.PIPE,
            stderr=subprocess.PIPE, preexec_fn=os.setsid
        )

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€Ðµ Ð¿Ð¾ ÐºÐ»ÑŽÑ‡Ñƒ user_id
        scrapy_processes[user_id] = scrapy_process

        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ° Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ
        atexit.register(handle_exit, user_id)
        return jsonify({"status": f"Scrapy spider started for user {user_id}."}), 200

    except Exception as e:
        return jsonify({
            "status": "Error in starting Scrapy spider.",
            "error": str(e)
        }), 500


def handle_exit(user_id):
    if user_id in scrapy_processes:
        scrapy_process = scrapy_processes[user_id]
        if scrapy_process.poll() is None:
            print(f" ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {user_id} Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½, Ð·Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Scrapy")
            os.killpg(os.getpgid(scrapy_process.pid), signal.SIGTERM)
        del scrapy_processes[user_id]  # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¸Ð· ÑÐ»Ð¾Ð²Ð°Ñ€Ñ

@app.route('/stop-scrapy', methods=['POST'])
def stop_scrapy():
    user_id = request.json.get("user_id")

    if user_id not in scrapy_processes or scrapy_processes[user_id].poll() is not None:
        return jsonify({"status": f"No running Scrapy process for user {user_id}."}), 400

    try:
        os.killpg(os.getpgid(scrapy_processes[user_id].pid), signal.SIGTERM)
        del scrapy_processes[user_id]  # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¸Ð· ÑÐ»Ð¾Ð²Ð°Ñ€Ñ
        return jsonify({"status": f"Scrapy spider stopped for user {user_id}."}), 200
    except Exception as e:
        return jsonify({
            "status": "Error stopping Scrapy spider.",
            "error": str(e)
        }), 500

# ðŸ”½ ÐÐ¾Ð²Ñ‹Ð¹ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚: ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð»Ð¾Ð³Ð¾Ð²
@app.route('/get-log', methods=['GET'])
def get_log():
    user_id = request.args.get("user_id")
    log_file_path = f"./catching_materials/logs/{user_id}_pipeline.log"

    timeout = 30  # ÑÐµÐºÑƒÐ½Ð´
    interval = 1  # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ°Ð¶Ð´ÑƒÑŽ ÑÐµÐºÑƒÐ½Ð´Ñƒ
    waited = 0

    while not os.path.exists(log_file_path) and waited < timeout:
        time.sleep(interval)
        waited += interval

    if not os.path.exists(log_file_path):
        return jsonify({"status": "Log file not found after waiting.", "user_id": user_id}), 404

    with open(log_file_path, 'r', encoding="utf-8", errors="ignore") as f:
        content = f.read()
    return jsonify({"status": "success", "log": content})

# ðŸ”½ ÐÐ¾Ð²Ñ‹Ð¹ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚: ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…
@app.route('/get-data', methods=['GET'])
def get_data():
    user_id = request.args.get("user_id")
    data_file_path = f"./catching_materials/data/{user_id}_data.json"

    timeout = 30
    interval = 1
    waited = 0

    while not os.path.exists(data_file_path) and waited < timeout:
        time.sleep(interval)
        waited += interval

    if not os.path.exists(data_file_path):
        return jsonify({"status": "Data file not found after waiting.", "user_id": user_id}), 404

    with open(data_file_path, 'r', encoding="utf-8", errors="ignore") as f:
        content = f.read()
    return jsonify({"status": "success", "data": content})

if __name__ == '__main__':
    app.run(debug=True, host="0.0.0.0", port=5000)
